{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jimmy93029/RL-theory-nycu/blob/main/test_loss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKQ4bH7qMGrA"
      },
      "source": [
        "# 充分發揮 Colab 訂閱的價值\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMMqmdiYMkvi"
      },
      "source": [
        "## 更快速的 GPU\n",
        "\n",
        "<p>使用者只要購買任一種 Colab 付費方案，就能使用付費 GPU。你可以在選單中依序按一下「執行階段」&gt;「變更執行階段類型」<code></code>啟用付費加速器，即可升級筆記本的 GPU 設定。在你選取付費 GPU 之後，系統會依據可用性授予 V100 或 A100 Nvidia GPU 的存取權。</p><p>如果使用的是免付費版 Colab，系統將依據配額限制和可用性授予 Nvidia 的 T4 GPU 存取權。</p>\n",
        "\n",
        "你隨時可以執行下列儲存格，瞭解目前系統指派給你的 GPU。如果下方程式碼儲存格的執行結果為「Not connected to a GPU」，你可以變更執行階段。請在選單中依序按一下「執行階段」&gt;「變更執行階段類型」<code></code>以啟用 GPU 加速器，然後重新執行程式碼儲存格。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23TOba33L4qf"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sa-IrJS1aRVJ"
      },
      "source": [
        "如要透過筆記本使用 GPU，請依序選取「執行階段」&gt;「變更執行階段類型」<code></code>選單，並將「硬體加速器」下拉式選單設為 GPU。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65MSuHKqNeBZ"
      },
      "source": [
        "## 更多記憶體\n",
        "\n",
        "使用者只要購買任一種 Colab 付費方案，一旦有大量記憶體的 VM 可供使用時，使用者就能存取。\n",
        "你可以透過執行以下程式碼儲存格，隨時查看有多少可用的記憶體。如果下方程式碼儲存格的執行結果為「Not using a high-RAM runtime」，你可以啟用大量 RAM 執行階段。請在選單中依序按一下「執行階段」&gt;「變更執行階段類型」<code></code>，並在「執行階段規格」下拉式選單中選取「大量 RAM」，然後重新執行程式碼儲存格。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1G82GuO-tez"
      },
      "outputs": [],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJW8Qi-pPpep"
      },
      "source": [
        "## 較長時間的執行階段\n",
        "\n",
        "所有 Colab 執行階段都會在一段時間後重設，如果執行階段並未執行程式碼，則會更快重設。與使用免付費版 Colab 的使用者相比，Colab Pro 和 Pro+ 使用者可以使用更長的執行階段。\n",
        "\n",
        "## 背景執行\n",
        "\n",
        "Colab Pro+ 為使用者提供背景執行功能，即使瀏覽器分頁已關閉，筆記本仍會持續執行。只要有可用的運算單元，Pro+ 執行階段一律會啟用這項功能。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLlTRcMM_h0k"
      },
      "source": [
        "## 在 Colab Pro 中放寬資源限制\n",
        "\n",
        "你在 Colab 中的資源設有上限。如要讓 Colab 發揮最大效益，請避免在非必要時使用資源。舉例來說，請只在必要時才使用 GPU，並在使用完畢後關閉 Colab 分頁。\n",
        "\n",
        "如果用量已達上限，你可以透過即付即用購買更多運算單元，以放寬這些限制。任何人都可以透過<a href=\"https://colab.research.google.com/signup\">即付即用</a>購買運算單元，不必訂閱方案。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm8FzEidvPs6"
      },
      "source": [
        "## 歡迎提供意見！\n",
        "\n",
        "<p>歡迎與我們分享你的寶貴意見，只要依序按一下「說明」&gt;「提供意見...」選單，即可提供意見。如果 Colab Pro 的用量已達上限，建議你訂閱 Pro+。</p>\n",
        "<p>如果 Colab Pro、Pro+ 或 Pay As You Go 的帳單 &#40;付款&#41; 發生錯誤或其他問題，請傳送電子郵件至 <a href=\"mailto:colab-billing@google.com\">colab-billing@google.com</a>。</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qB3bdLe8jkAa"
      },
      "source": [
        "## 其他資源\n",
        "\n",
        "### 在 Colab 中使用筆記本\n",
        "- [Colaboratory 總覽](/notebooks/basic_features_overview.ipynb)\n",
        "- [Markdown 指南](/notebooks/markdown_guide.ipynb)\n",
        "- [匯入程式庫及安裝依附元件](/notebooks/snippets/importing_libraries.ipynb)\n",
        "- [儲存和載入 GitHub 中的筆記本](https://colab.research.google.com/github/googlecolab/colabtools/blob/main/notebooks/colab-github-demo.ipynb)\n",
        "- [互動式表單](/notebooks/forms.ipynb)\n",
        "- [互動式小工具](/notebooks/widgets.ipynb)\n",
        "\n",
        "<a name=\"working-with-data\"></a>\n",
        "### 處理資料\n",
        "- [載入資料：雲端硬碟、試算表及 Google Cloud Storage](/notebooks/io.ipynb)\n",
        "- [圖表：將資料視覺化](/notebooks/charts.ipynb)\n",
        "- [開始使用 BigQuery](/notebooks/bigquery.ipynb)\n",
        "\n",
        "### 機器學習密集課程\n",
        "以下是一些 Google 線上機器學習課程的筆記本。詳情請參閱<a href=\"https://developers.google.com/machine-learning/crash-course/\">完整的課程網站</a>。\n",
        "- [Pandas DataFrame 簡介](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/pandas_dataframe_ultraquick_tutorial.ipynb)\n",
        "- [以 tf.keras 使用合成資料進行線性迴歸](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/linear_regression_with_synthetic_data.ipynb)\n",
        "\n",
        "\n",
        "<a name=\"using-accelerated-hardware\"></a>\n",
        "### 使用加速硬體\n",
        "- [搭配 GPU 使用 TensorFlow](/notebooks/gpu.ipynb)\n",
        "- [使用 TPU 的 TensorFlow](/notebooks/tpu.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFm2S0Gijqo8"
      },
      "source": [
        "<a name=\"machine-learning-examples\"></a>\n",
        "\n",
        "## 機器學習範例\n",
        "\n",
        "如想瞭解 Colaboratory 支援的互動式機器學習分析端對端範例，請參閱這些使用 <a href=\"https://tfhub.dev\">TensorFlow Hub</a> 模型的教學課程。\n",
        "\n",
        "一些精選範例如下：\n",
        "\n",
        "- <a href=\"https://tensorflow.org/hub/tutorials/tf2_image_retraining\">重新訓練圖片分類工具</a>：以預先訓練的圖片分類工具為基礎，建立一個分辨花朵的 Keras 模型。\n",
        "- <a href=\"https://tensorflow.org/hub/tutorials/tf2_text_classification\">文字分類</a>：將 IMDB 電影評論分類為<em>正面</em>或<em>負面</em>。\n",
        "- <a href=\"https://tensorflow.org/hub/tutorials/tf2_arbitrary_image_stylization\">風格轉換</a>：運用深度學習轉換圖片的風格。\n",
        "- <a href=\"https://tensorflow.org/hub/tutorials/retrieval_with_tf_hub_universal_encoder_qa\">支援多種語言的 Universal Sentence Encoder 問與答</a>：使用機器學習模型來回答 SQuAD 資料集的問題。\n",
        "- <a href=\"https://tensorflow.org/hub/tutorials/tweening_conv3d\">影片畫面內插</a>：預測影片在第一個與最後一個畫面之間的內容。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "NIYqACGtmbhM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Sebf3fcCrli8",
        "outputId": "87dcef97-470a-4311-d736-c68c5c2cc5db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def quantile_regression_loss(input, target, prob, expectile):\n",
        "    \"\"\"\n",
        "    input: (N, T)\n",
        "    target: (N, T)\n",
        "    tau: (N, T)\n",
        "    \"\"\"\n",
        "    input = input.unsqueeze(-1)\n",
        "    target = target.detach().unsqueeze(-2)\n",
        "    tau = tau.detach().unsqueeze(-1)\n",
        "    weight = weight.detach().unsqueeze(-2)\n",
        "\n",
        "    expanded_input, expanded_target = torch.broadcast_tensors(input, target)\n",
        "    L = F.mse_loss(expanded_input, expanded_target, reduction=\"none\")  # (N, T, T)\n",
        "\n",
        "\n",
        "    sign = -torch.sign(expanded_input - expanded_target) / 2. + 0.5\n",
        "    rho = torch.abs(tau - sign) * L * weight\n",
        "\n",
        "    return rho.sum(dim=-1).mean()\n"
      ],
      "metadata": {
        "id": "V2VVSQOjmay1"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lossV1(q, v, presum_tau, expectile=0.8):\n",
        "    batch_size, quantile_size = q.size()\n",
        "\n",
        "    diff = q.unsqueeze(2) - v.unsqueeze(1)              # Shape: (batch_size, quantile_size, quantile_size)\n",
        "    weight = torch.where(diff < 0, 1 - expectile, expectile)   # Shape: (batch_size, quantile_size, quantile_size)\n",
        "\n",
        "    presum_tau_outer = presum_tau.unsqueeze(2) * presum_tau.unsqueeze(1)  # Shape: (batch_size, quantile_size, quantile_size)\n",
        "\n",
        "    loss = weight * (diff ** 2) * presum_tau_outer  # Shape: (batch_size, quantile_size, quantile_size)\n",
        "\n",
        "    print(f\"L = {diff ** 2}\")\n",
        "    print(f\"weight = {weight}\")\n",
        "    print(f\"prob = {presum_tau_outer}\")\n",
        "    print(f\"o loss = {loss}\")\n",
        "    print(f\"loss sum = {loss.sum(dim=2)}\")\n",
        "\n",
        "    loss = loss.sum(dim=1).mean()\n",
        "\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "id": "STkKlYTymkvE"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample tensors for testing\n",
        "input_tensor = torch.tensor([[2.0, 2.0, 2.0], [2.0, 2.0, 2.0]])\n",
        "target_tensor = torch.tensor([[1.0, 1.0, 1.0], [1.0, 1.0, 1.0]])\n",
        "tau_tensor = torch.tensor(1)\n",
        "weight_tensor = torch.tensor([[0.2, 0.7, 0.1], [0.3, 0.6, 0.1]])\n",
        "\n",
        "# Call the function\n",
        "loss = quantile_regression_loss(input_tensor, target_tensor, tau_tensor, weight_tensor)\n",
        "print(\"--------------------------------------------------------------------\")\n",
        "losssv = lossV1(input_tensor, target_tensor, weight_tensor, tau_tensor)\n",
        "\n",
        "# Print the output\n",
        "print(f\"Quantile Regression Loss: {loss.item()}\")\n",
        "print(f\"v1 Loss: {losssv.item()}\")"
      ],
      "metadata": {
        "id": "47zvg1s3mjYT",
        "outputId": "86da494f-a846-4478-80a2-768e52511575",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prob = torch.Size([2, 1, 3])\n",
            "L = tensor([[[1., 1., 1.],\n",
            "         [1., 1., 1.],\n",
            "         [1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1.],\n",
            "         [1., 1., 1.],\n",
            "         [1., 1., 1.]]])\n",
            "weight = tensor([[[1., 1., 1.],\n",
            "         [1., 1., 1.],\n",
            "         [1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1.],\n",
            "         [1., 1., 1.],\n",
            "         [1., 1., 1.]]])\n",
            "prob = tensor([[[0.2000, 0.7000, 0.1000]],\n",
            "\n",
            "        [[0.3000, 0.6000, 0.1000]]])\n",
            "o loss = tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "--------------------------------------------------------------------\n",
            "L = tensor([[[1., 1., 1.],\n",
            "         [1., 1., 1.],\n",
            "         [1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1.],\n",
            "         [1., 1., 1.],\n",
            "         [1., 1., 1.]]])\n",
            "weight = tensor([[[1, 1, 1],\n",
            "         [1, 1, 1],\n",
            "         [1, 1, 1]],\n",
            "\n",
            "        [[1, 1, 1],\n",
            "         [1, 1, 1],\n",
            "         [1, 1, 1]]])\n",
            "prob = tensor([[[0.0400, 0.1400, 0.0200],\n",
            "         [0.1400, 0.4900, 0.0700],\n",
            "         [0.0200, 0.0700, 0.0100]],\n",
            "\n",
            "        [[0.0900, 0.1800, 0.0300],\n",
            "         [0.1800, 0.3600, 0.0600],\n",
            "         [0.0300, 0.0600, 0.0100]]])\n",
            "o loss = tensor([[[0.0400, 0.1400, 0.0200],\n",
            "         [0.1400, 0.4900, 0.0700],\n",
            "         [0.0200, 0.0700, 0.0100]],\n",
            "\n",
            "        [[0.0900, 0.1800, 0.0300],\n",
            "         [0.1800, 0.3600, 0.0600],\n",
            "         [0.0300, 0.0600, 0.0100]]])\n",
            "loss sum = tensor([[0.2000, 0.7000, 0.1000],\n",
            "        [0.3000, 0.6000, 0.1000]])\n",
            "Quantile Regression Loss: 1.0\n",
            "v1 Loss: 0.3333333432674408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def q_minus_v(q, v, presum_tau):\n",
        "    \"\"\"\n",
        "    q: (N, T)\n",
        "    v: (N, T)\n",
        "    presum_tau: (N, T)\n",
        "    \"\"\"\n",
        "    presum_tau_outer = presum_tau.unsqueeze(2) * presum_tau.unsqueeze(1)  # Shape: (N, T, T)\n",
        "\n",
        "    diff = q.unsqueeze(2) - v.unsqueeze(1)  # Shape: (N, T, T)\n",
        "\n",
        "    weighted_diff = diff * presum_tau_outer  # Shape: (N, T, T)\n",
        "\n",
        "    loss = weighted_diff.sum(dim=(1, 2))  # Sum over dimensions 1 and 2\n",
        "\n",
        "    return loss.mean()"
      ],
      "metadata": {
        "id": "BBKZFvqOEfNP"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample tensors for testing\n",
        "q_tensor = torch.tensor([[2.0, 2.0, 2.0], [2.0, 2.0, 2.0]])\n",
        "v_tensor = torch.tensor([[1.0, 1.0, 1.0], [1.0, 1.0, 1.0]])\n",
        "presum_tau_tensor = torch.tensor([[0.1, 0.8, 0.1], [0.4, 0.5, 0.1]])\n",
        "\n",
        "# Call the function\n",
        "loss = q_minus_v(q_tensor, v_tensor, presum_tau_tensor)\n",
        "\n",
        "# Print the output\n",
        "print(f\"q_minus_v Loss: {loss.item()}\")"
      ],
      "metadata": {
        "id": "XsryFW9RJLlz",
        "outputId": "f0f37c33-fe7b-4afd-c15c-15f77c0c1965",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "q_minus_v Loss: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eik8N-VpJMeG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "充分發揮 Colab 訂閱的價值",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}